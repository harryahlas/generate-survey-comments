{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seqcomments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "15hC4G1-CxA4Lj2GGP8hZxUiepTQ2Tofs",
      "authorship_tag": "ABX9TyMKBA62PvYYOFfi4Id0ZFQA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harryahlas/generate-survey-comments/blob/master/seq2seqcomments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbUHj2DLCaD-"
      },
      "source": [
        "# Generate Survey Comments\r\n",
        "Builds a sequence to sequence model to create comments resembling responses from employee surveys.  Training data (*training_comments.csv*, stored in my personal Google Drive and available on request) was pulled from multiple online sources, mostly *data.world*. I truncated the comments at 1000 characters to facilitate training.\r\n",
        "\r\n",
        "The model is based on the work of George Pipis, link below.\r\n",
        "\r\n",
        "https://pub.towardsai.net/word-level-text-generation-dd61a5a0313d\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7xUE0dOghvn"
      },
      "source": [
        "#### Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NViZDC0RBsk",
        "outputId": "5791c1f0-f129-4250-9140-44f67cfa3b7f"
      },
      "source": [
        "# Mount Drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7AF3zSjgR-Y"
      },
      "source": [
        "#### Load Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3D-DhJKCVXE"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras import regularizers\r\n",
        "import tensorflow.keras.utils as ku \r\n",
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxROo2z8gOff"
      },
      "source": [
        "#### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRX_FVdHCeOC",
        "outputId": "3d42c4ec-742f-4b02-eba9-791db740ca2e"
      },
      "source": [
        "tokenizer = Tokenizer()\r\n",
        "data = open('training_comments.csv').read()\r\n",
        "corpus = data.lower().split(\"\\n\")\r\n",
        "tokenizer.fit_on_texts(corpus)\r\n",
        "total_words = len(tokenizer.word_index) + 1\r\n",
        "# create input sequences using list of tokens\r\n",
        "input_sequences = []\r\n",
        "for line in corpus:\r\n",
        " token_list = tokenizer.texts_to_sequences([line])[0]\r\n",
        " for i in range(1, len(token_list)):\r\n",
        "  n_gram_sequence = token_list[:i+1]\r\n",
        "  input_sequences.append(n_gram_sequence)\r\n",
        "# pad sequences \r\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\r\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\r\n",
        "# create predictors and label\r\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\r\n",
        "label = ku.to_categorical(label, num_classes=total_words)\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\r\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(LSTM(100))\r\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\r\n",
        "model.add(Dense(total_words, activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\r\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(LSTM(100))\r\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\r\n",
        "model.add(Dense(total_words, activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "print(model.summary())\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 201, 100)          796400    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 201, 300)          301200    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 201, 300)          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3982)              402182    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 7964)              31720612  \n",
            "=================================================================\n",
            "Total params: 33,380,794\n",
            "Trainable params: 33,380,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EwVnHQ3fk8z"
      },
      "source": [
        "#### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9x9g0ewDTXf",
        "outputId": "c0808765-d71b-4168-f1e1-d76c3864bb3b"
      },
      "source": [
        "history = model.fit(predictors, label, epochs=1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 963/3180 [========>.....................] - ETA: 42:56 - loss: 6.5005 - accuracy: 0.0666"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kcd0kZSftFG"
      },
      "source": [
        "#### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjA8xFeNUmpB"
      },
      "source": [
        "model.save('/content/gdrive/My Drive/Development/seq2seqcomments/seq2seq50')\r\n",
        "#model_backup = model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEM9ilj-f1Db"
      },
      "source": [
        "#### Load Model from Drive *(Optional)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajAAPgCDaSCw"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "model = keras.models.load_model('/content/gdrive/My Drive/Development/seq2seqcomments/seq2seq50')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ3cNAHof9H4"
      },
      "source": [
        "#### Function to Predict Words *print_next_words()*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Naj51EqyeVnF"
      },
      "source": [
        "def print_next_words(seed_text,number_of_words_to_predict):\r\n",
        "  for _ in range(number_of_words_to_predict):\r\n",
        "   token_list = tokenizer.texts_to_sequences([seed_text])[0]\r\n",
        "   token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\r\n",
        "   predicted = model.predict_classes(token_list, verbose=0)\r\n",
        "   output_word = \"\"\r\n",
        "   for word, index in tokenizer.word_index.items():\r\n",
        "    if index == predicted:\r\n",
        "     output_word = word\r\n",
        "     break\r\n",
        "   seed_text += \" \" + output_word\r\n",
        "  print(seed_text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB6ExtjcgFqR"
      },
      "source": [
        "#### Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnbhbwJ2aa3f",
        "outputId": "6fe9a7be-1b5b-46e3-e909-bde5d684b571"
      },
      "source": [
        "print_next_words(\"my manager is good at\", 30)\r\n",
        "print_next_words(\"I should be paid more.\", 30)\r\n",
        "print_next_words(\"The customer service\", 30)\r\n",
        "print_next_words(\"My benefits are good but I wish there was better life insurance.\", 30)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "my manager is good at the city to the city to the city to the city to the city to the city to the city to the city to the city to the city to\n",
            "I should be paid more. the city to the city to the city to the city to the city to the city to the city to the city to the city to the city to\n",
            "The customer service and the city to the city to the city to the city to the city to the city to the city to the city to the city to the city\n",
            "My benefits are good but I wish there was better life insurance. and the city to the city to the city to the city to the city to the city to the city to the city to the city to the city\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}